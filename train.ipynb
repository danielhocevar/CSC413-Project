{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "from numpy.random import choice, seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models import BasicTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from preprocess_data import *\n",
    "\n",
    "with open('action_types.json', 'r') as f:\n",
    "    action_types = json.load(f)\n",
    "    \n",
    "df = (\n",
    "    pd.read_csv(\"WSL_actions.csv\", index_col = 0)\n",
    "    .pipe(add_coordinate_bins, n_bins_x = 10, n_bins_y = 10)\n",
    "    .pipe(add_team_as_dummy)\n",
    "    .pipe(get_action_type_names, action_types)\n",
    "    .pipe(get_action_tokens)\n",
    "    .assign(\n",
    "        group_id = lambda d: d.groupby(['game_id', 'period_id']).ngroup(),\n",
    "        action_token = lambda d: pd.Categorical(d.action_token)\n",
    "    )\n",
    "    [['group_id', 'action_token']]\n",
    ")\n",
    "\n",
    "vocab = df['action_token'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 55, 363, 406, 428, 402], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed(42)\n",
    "train_groups = choice(df['group_id'].unique(), int(0.8 * df['group_id'].nunique()), replace = False)\n",
    "val_groups = choice(train_groups, int(0.8 * len(train_groups)), replace = False)\n",
    "train_groups[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.query(\"group_id.isin(@train_groups) and ~group_id.isin(@val_groups)\")\n",
    "val_df = df.query(\"group_id.isin(@val_groups)\")\n",
    "\n",
    "X_train = np.lib.stride_tricks.sliding_window_view(train_df['action_token'].map(list(vocab).index), (3,))[:-1]\n",
    "y_train = np.lib.stride_tricks.sliding_window_view(train_df['action_token'].map(list(vocab).index), (3,))[1:]\n",
    "\n",
    "X_val = np.lib.stride_tricks.sliding_window_view(val_df['action_token'].map(list(vocab).index), (3,))[:-1]\n",
    "y_val = np.lib.stride_tricks.sliding_window_view(val_df['action_token'].map(list(vocab).index), (3,))[1:]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    list(zip(X_train, y_train)),\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    list(zip(X_val, y_val)),\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    return sum(preds[:, -1].argmax(dim=1) == labels[:, -1].argmax(dim=1)) / len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, n_epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        i = 0\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        for x_bat, y_bat in iter(train_loader):\n",
    "            x_bat.permute(1, 0)\n",
    "            y_bat = F.one_hot(y_bat, num_classes=len(vocab)).float()\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_bat)\n",
    "            loss = criterion(y_pred, y_bat)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            i += 1\n",
    "            train_acc += accuracy(y_pred, y_bat)\n",
    "        \n",
    "            # print(f'Epoch {epoch}, iter {i}, loss: {loss.item()}')\n",
    "        train_acc = train_acc / len(train_loader)\n",
    "\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        for x_val, y_val in iter(val_loader):\n",
    "            y_pred = model(x_val)\n",
    "            y_val = F.one_hot(y_val, num_classes=len(vocab)).float()\n",
    "            loss = criterion(y_pred, y_val)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += accuracy(y_pred, y_val)\n",
    "        \n",
    "        val_acc = val_acc / len(val_loader)\n",
    "        print(f'Epoch {epoch}, iter {i}, train_loss: {train_loss}, train_acc: {train_acc}, val_loss: {val_loss}, val_acc: {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicTransformer(len(vocab), 128, 128, 2, 2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ethan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:171: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"transformer_weights.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc413",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
